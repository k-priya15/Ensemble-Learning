{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Learning Assignment"
      ],
      "metadata": {
        "id": "urts2IP6SAJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Assignment Questions"
      ],
      "metadata": {
        "id": "hm3dLKpUm-sO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical\n"
      ],
      "metadata": {
        "id": "s395pPeBq_gL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q1) Can we use Bagging for regression problems?\n",
        "\n",
        "Yes, bagging (Bootstrap Aggregating) can be used for regression tasks as well as classification. In regression, multiple base regressors (like Decision Trees) are trained on different bootstrapped samples of the training data. Their predictions are then averaged to produce the final output. This averaging helps reduce variance and improve the model’s stability. Bagging is particularly effective for high-variance models like decision trees. It prevents overfitting and enhances generalization. Popular implementations include BaggingRegressor and Random Forest Regressor in scikit-learn."
      ],
      "metadata": {
        "id": "_Paa8myZvgHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "22jmk71F-lNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2) What is the difference between multiple model training and single model training?\n",
        "\n",
        "Single model training involves building and training one model on the entire dataset, which then makes predictions alone. Multiple model training (ensemble learning) combines predictions from several models to improve accuracy, robustness, and generalization. Ensembles like Bagging, Boosting, and Stacking leverage multiple models’ strengths and reduce weaknesses. This approach reduces variance and bias, leading to more stable results. However, it’s computationally more expensive than training a single model."
      ],
      "metadata": {
        "id": "NQ4qB9bSvp-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "azZUk2uQ-t1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q3) Explain the concept of feature randomness in Random Forest.\n",
        "\n",
        "Feature randomness is a key concept in Random Forest that enhances diversity among trees. Instead of considering all features for the best split at each node, Random Forest randomly selects a subset of features. This randomness prevents all trees from becoming similar and reduces correlation among them. It helps improve model generalization and reduces overfitting. As a result, even if one feature dominates the data, others still get a chance to influence the model. This technique improves the ensemble’s overall predictive power."
      ],
      "metadata": {
        "id": "NviEDIScv-Xr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Vojnm6kT-vL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q4) What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "The Out-of-Bag (OOB) score is a built-in cross-validation method used in bagging techniques like Random Forest. Since each tree is trained on a bootstrapped sample (about 63% of data), the remaining ~37% (OOB samples) can serve as a validation set. The model’s performance on these OOB samples is aggregated to estimate its accuracy. OOB scoring eliminates the need for a separate validation set, saving data and computation. It’s a reliable and unbiased estimate of model performance."
      ],
      "metadata": {
        "id": "Q9yqVwnawHIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "spxMThJP-wP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q5 - How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "Random Forest provides feature importance scores based on how much each feature reduces impurity (like Gini or entropy) across all trees. A feature’s importance is calculated as the total decrease in impurity it contributes, averaged over all splits where it’s used. Another method is permutation importance, which measures the drop in model accuracy when a feature’s values are randomly shuffled. Both approaches help identify key predictors, aiding feature selection and interpretability."
      ],
      "metadata": {
        "id": "nZ5dL8h1wLA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sOwacEDX-xku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q6) Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "A Bagging Classifier builds multiple instances of a base classifier (e.g., Decision Trees) on different bootstrapped subsets of the training data. Each classifier independently learns patterns and makes predictions. The final prediction is typically determined by majority voting among all models. This ensemble approach reduces variance and improves robustness compared to a single model. It’s particularly useful for unstable models prone to overfitting. Bagging also enhances generalization without significantly increasing bias."
      ],
      "metadata": {
        "id": "Hjv6cjB6xCkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3ERHrKi-zOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q7) How do you evaluate a Bagging Classifier’s performance?\n",
        "\n",
        "The performance of a Bagging Classifier is evaluated using standard classification metrics like accuracy, precision, recall, F1-score, and the confusion matrix. Cross-validation can also be applied to get more reliable estimates. Additionally, the OOB score is a convenient way to assess model accuracy without a separate validation set. Visualization of ROC-AUC curves and precision-recall curves is helpful for imbalanced data. Comparing results against a single base model shows the improvement gained from bagging."
      ],
      "metadata": {
        "id": "sdv5g2iJxG3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SiOG6P6G-5xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q8) How does a Bagging Regressor work?\n",
        "\n",
        "A Bagging Regressor follows the same principle as a Bagging Classifier but for regression tasks. It trains multiple base regressors on different bootstrapped samples of the data. Each regressor produces a continuous prediction, and the final output is the average of all predictions. This ensemble approach reduces variance and improves predictive stability. It is especially effective for high-variance models like decision trees. Bagging can also improve performance on noisy datasets."
      ],
      "metadata": {
        "id": "Cu-SG0ljxKga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L6sNglT2-67-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q9 - What is the main advantage of ensemble techniques?\n",
        "\n",
        "The main advantage of ensemble methods is their ability to improve model performance by combining multiple models’ strengths. They often achieve higher accuracy, better generalization, and increased robustness compared to single models. Ensembles can reduce variance (bagging), reduce bias (boosting), or balance both (stacking). They’re less prone to overfitting and usually outperform individual models in complex problems. This makes them widely used in real-world applications like finance, healthcare, and recommendation systems."
      ],
      "metadata": {
        "id": "BJRWsR6pxW92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1eLXPx4l-74Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q10 - What is the main challenge of ensemble methods?\n",
        "\n",
        "The primary challenge of ensemble techniques is their computational complexity. Training multiple models requires more time and resources than a single model. They can also be harder to interpret, as the final decision is a result of many models’ outputs. Hyperparameter tuning and model selection become more complicated. Additionally, ensembles risk overfitting if not properly regularized or if weak learners are too complex. Despite these challenges, their performance benefits often outweigh the drawbacks."
      ],
      "metadata": {
        "id": "HNRp-mw2xmMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5O9jYBRB-9F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q11 - Explain the key idea behind ensemble techniques?\n",
        "\n",
        "The key idea behind ensemble techniques is to combine multiple models to create a stronger, more accurate, and more robust predictive model than any single model alone. Individual models, called base learners or weak learners, may have high bias, high variance, or limited predictive power. However, when combined, they can complement each other’s strengths and compensate for their weaknesses.\n",
        "Ensemble learning works on the principle that “the wisdom of the crowd” is often more accurate than the opinion of a single member. Techniques like Bagging reduce variance by averaging predictions from many models trained on different data samples. Boosting reduces bias by sequentially training models where each one focuses on correcting the errors of the previous one. Stacking combines different types of models to leverage their diverse learning capabilities.\n",
        "Overall, ensemble methods increase accuracy, improve generalization, handle noise better, and are more robust in real-world scenarios. They are widely used in applications like fraud detection, medical diagnosis, stock market prediction, and recommendation systems. However, they require more computational resources and are harder to interpret. Despite that, their performance improvements make them one of the most powerful tools in machine learning."
      ],
      "metadata": {
        "id": "A7c4RazMx3PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kpVFKlIV--Kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q12 - What is a Random Forest Classifier?\n",
        "\n",
        "A Random Forest Classifier is an ensemble learning algorithm that builds multiple decision trees and combines their predictions to improve classification accuracy and robustness. It works on the principle of bagging (bootstrap aggregating) and feature randomness. Each tree is trained on a random subset of the training data and considers a random subset of features when splitting nodes.\n",
        "During prediction, all trees vote, and the class with the majority vote becomes the final output. This reduces the risk of overfitting that a single decision tree might suffer from. Random Forests also provide a measure of feature importance, helping us understand which features contribute most to the prediction.\n",
        "It’s highly versatile and can handle large datasets, missing values, categorical and numerical data. It is less sensitive to noise and performs well even with default parameters. The algorithm is widely used in credit scoring, spam detection, medical diagnosis, and recommendation systems.\n",
        "Its key advantages include improved accuracy, reduced variance, and good generalization. However, it can be computationally expensive and harder to interpret compared to a single tree."
      ],
      "metadata": {
        "id": "IVYL2xuL8eg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AgiWvhID-_UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q13 - What are the main types of ensemble techniques?\n",
        "\n",
        "Ensemble techniques can be broadly categorized into three main types: Bagging, Boosting, and Stacking.\n",
        "\n",
        "Bagging (Bootstrap Aggregating): It involves training multiple models on different random subsets of the data (with replacement) and combining their predictions through voting (classification) or averaging (regression). Examples: Random Forest, BaggingClassifier.\n",
        "\n",
        "Boosting: It builds models sequentially, where each new model focuses on correcting the mistakes of the previous ones. Boosting reduces bias and improves performance. Examples: AdaBoost, Gradient Boosting, XGBoost, LightGBM.\n",
        "\n",
        "Stacking (Stacked Generalization): It combines predictions from multiple different models (e.g., decision trees, logistic regression, SVM) using a meta-learner that learns how to best combine them.\n",
        "\n",
        "Other variations include Voting Classifiers (simple majority/weighted voting) and Blending (similar to stacking but uses a holdout set). Each technique has its own strengths — Bagging reduces variance, Boosting reduces bias, and Stacking leverages multiple model types. The choice depends on data size, complexity, and performance goals."
      ],
      "metadata": {
        "id": "ndBDGeug8h05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5FuOuMWS_AfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q14 - What is ensemble learning in machine learning?\n",
        "\n",
        "Ensemble learning is a machine learning technique that combines multiple models to produce a stronger predictive model with better accuracy, generalization, and stability. The fundamental idea is that a group of weak learners can collectively act as a strong learner.\n",
        "Instead of relying on one model, ensemble methods aggregate the predictions of several models through techniques like voting, averaging, or weighted combinations. This approach reduces the risk of overfitting, bias, and variance simultaneously.\n",
        "There are three major forms of ensemble learning: Bagging, Boosting, and Stacking. Bagging trains models in parallel on random subsets of data, Boosting trains them sequentially focusing on errors, and Stacking blends different models using a meta-model.\n",
        "Ensemble methods are highly effective in solving complex problems and are often used in competitions like Kaggle due to their superior performance. They are widely used in domains like healthcare, finance, fraud detection, and recommendation systems.\n",
        "However, they are computationally expensive, harder to interpret, and may require extensive hyperparameter tuning. Despite these drawbacks, ensemble learning remains a cornerstone of modern predictive analytics and machine learning."
      ],
      "metadata": {
        "id": "1DYqxvj-8lBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6bU9SwIb_B0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q15 - When should we avoid using ensemble methods?\n",
        "\n",
        "While ensemble methods are powerful, there are certain situations where they might not be ideal. If the dataset is small or simple, a single well-tuned model might perform just as well without the added complexity. Ensemble models are computationally expensive, requiring more memory and training time, so they may not be suitable for real-time or resource-constrained environments.\n",
        "They also make the model harder to interpret — if explainability is a priority (like in healthcare or finance), simpler models like logistic regression or decision trees are preferred. Overfitting can occur if base models are too complex or if ensembles are not properly regularized.\n",
        "In cases where quick deployment and interpretability are critical, a single model may be better. Additionally, if the performance gain from an ensemble is marginal compared to a single model, the added complexity might not justify the trade-off.\n",
        "In short, ensemble methods should be avoided when interpretability, computational cost, simplicity, or data size constraints outweigh the need for higher accuracy."
      ],
      "metadata": {
        "id": "wSAYmiKW8wBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ewNS08jg_DAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q16 - How does Bagging help in reducing overfitting?\n",
        "\n",
        "Bagging helps reduce overfitting by training multiple models on different random bootstrapped subsets of the training data. Since each model sees a slightly different dataset, they learn slightly different patterns. When their predictions are combined (by averaging or voting), the variance of the final model decreases.\n",
        "This ensemble approach ensures that errors specific to individual models are averaged out, leading to more stable and generalized predictions. Bagging is particularly effective for high-variance models like decision trees, which tend to overfit the training data.\n",
        "It also reduces sensitivity to noise, as not all models are influenced by the same outliers. As a result, the ensemble performs better on unseen data. Additionally, the diversity created by bootstrapping ensures that models complement each other’s weaknesses.\n",
        "Random Forest is a classic example of how bagging reduces overfitting while maintaining strong predictive performance. This makes bagging a go-to technique when overfitting is a major concern."
      ],
      "metadata": {
        "id": "RaHu0pq98xdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WrQMBLEY_E9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q17 - Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "Random Forest is often better than a single decision tree because it reduces variance, improves generalization, and delivers higher accuracy. A single tree can easily overfit, learning noise and patterns specific to the training data. Random Forest mitigates this by building multiple trees on different bootstrapped samples and averaging their predictions.\n",
        "It introduces randomness in feature selection, which ensures that trees are diverse and less correlated. This diversity makes the ensemble more robust and stable. Random Forest also provides a built-in estimate of feature importance, helping with feature selection and interpretability.\n",
        "It handles missing data, categorical and numerical variables, and large datasets effectively. Additionally, it is less sensitive to noise and outliers compared to a single tree.\n",
        "Overall, Random Forest strikes a balance between bias and variance, offering better accuracy and generalization. The trade-off is higher computational cost and reduced interpretability, but the performance benefits usually outweigh these drawbacks."
      ],
      "metadata": {
        "id": "z0wA787h80kS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hFJEr9TA_GGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q18 - What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "Bootstrap sampling is the foundation of the bagging technique. It involves creating multiple training datasets by randomly sampling (with replacement) from the original dataset. Each new dataset (called a bootstrap sample) is likely to contain some repeated instances and some excluded ones.\n",
        "This randomness ensures that each model is trained on a slightly different subset of the data, introducing diversity among the base learners. The diversity is crucial because it reduces the correlation between models, lowering variance when predictions are aggregated.\n",
        "Bootstrap sampling also allows us to estimate model performance using Out-of-Bag (OOB) samples (data not included in a particular bootstrap sample). This eliminates the need for a separate validation set.\n",
        "The ensemble prediction, typically an average or majority vote, leverages this diversity to achieve better generalization. Without bootstrap sampling, all models would see the same data, leading to similar predictions and reduced ensemble effectiveness."
      ],
      "metadata": {
        "id": "kUk5zBep84gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0sm25YwB_JeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q19 - What are some real-world applications of ensemble techniques?\n",
        "\n",
        "Ensemble methods are widely used in real-world applications across various industries due to their high accuracy and robustness. In finance, they are used for credit scoring, fraud detection, and stock price prediction. In healthcare, they help in disease diagnosis, patient risk prediction, and medical image classification.\n",
        "In e-commerce, ensembles power recommendation systems, customer segmentation, and churn prediction. Cybersecurity uses them for intrusion detection and malware classification. They are also crucial in natural language processing tasks like sentiment analysis, spam detection, and text classification.\n",
        "In self-driving cars, ensemble models improve object detection and decision-making accuracy. Manufacturing uses them for predictive maintenance and quality control.\n",
        "Ensembles are often the winning approaches in data science competitions (like Kaggle) because they consistently outperform single models. Their ability to handle complex, noisy, and high-dimensional data makes them highly valuable in solving real-world business problems."
      ],
      "metadata": {
        "id": "JzijlUrG87rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gtf8XqH__Kiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q20 - What is the difference between Bagging and Boosting?\n",
        "\n",
        "Bagging and Boosting are both ensemble methods but differ fundamentally in how they train models and combine results.\n",
        "\n",
        "Bagging (Bootstrap Aggregating): Trains multiple models in parallel on different bootstrapped subsets of data. Each model is independent, and their results are combined by averaging (regression) or voting (classification). Bagging mainly reduces variance and improves stability. Random Forest is a classic example.\n",
        "\n",
        "Boosting: Trains models sequentially, where each new model focuses on correcting the errors of the previous ones. It gives more weight to misclassified instances, reducing bias and improving accuracy. Examples include AdaBoost, Gradient Boosting, and XGBoost.\n",
        "\n",
        "Bagging is less prone to overfitting but may not significantly improve bias, while Boosting often achieves higher accuracy but risks overfitting if not regularized.\n",
        "\n",
        "Bagging is simpler and faster, while Boosting is more powerful but computationally expensive. Both are valuable, and the choice depends on the dataset and performance requirements."
      ],
      "metadata": {
        "id": "V9g2jN6q9JlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SuYeYGRI_LgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "EERpdIR3y5oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q21: Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Bagging Classifier\n",
        "bag_clf = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Accuracy\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3D_i32Ddyu-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q22: Train a Bagging Regressor using Decision Trees and evaluate using MSE\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load data\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Bagging Regressor\n",
        "bag_reg = BaggingRegressor(\n",
        "    base_estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Evaluate\n",
        "y_pred = bag_reg.predict(X_test)\n",
        "print(\"Bagging Regressor MSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "vkgAwbDozGou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q23: Train a Random Forest Classifier on Breast Cancer dataset and print feature importance\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "importances = pd.Series(rf_clf.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
        "print(\"Feature Importances:\\n\", importances)"
      ],
      "metadata": {
        "id": "dl2bUuAhzRv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q24: Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "# Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "dt_pred = dt_reg.predict(X_test)\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_reg = RandomForestClassifier(random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))"
      ],
      "metadata": {
        "id": "O09B3nuxzZ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q25: Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "rf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_oob.fit(X_train, y_train)\n",
        "print(\"OOB Score:\", rf_oob.oob_score_)"
      ],
      "metadata": {
        "id": "Df-wmlpdziGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q26: Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "bag_svm = BaggingClassifier(\n",
        "    base_estimator=SVC(),\n",
        "    n_estimators=30,\n",
        "    random_state=42\n",
        ")\n",
        "bag_svm.fit(X_train, y_train)\n",
        "y_pred = bag_svm.predict(X_test)\n",
        "print(\"Bagging SVM Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "pKwhZu0Rzmjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q27: Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "for trees in [10, 50, 100, 200]:\n",
        "    rf = RandomForestClassifier(n_estimators=trees, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "    print(f\"Trees: {trees} --> Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "QTcSCP_ZzrL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q28: Train a Bagging Classifier using Logistic Regression as base estimator and print AUC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "bag_log = BaggingClassifier(\n",
        "    base_estimator=LogisticRegression(max_iter=1000),\n",
        "    n_estimators=30,\n",
        "    random_state=42\n",
        ")\n",
        "bag_log.fit(X_train, y_train)\n",
        "y_prob = bag_log.predict_proba(X_test)[:, 1]\n",
        "print(\"Bagging Logistic Regression AUC:\", roc_auc_score(y_test, y_prob))"
      ],
      "metadata": {
        "id": "RIGFj0L2zu9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q29: Train a Random Forest Regressor and analyze feature importance\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load regression dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "importances = pd.Series(rf_reg.feature_importances_)\n",
        "print(\"Feature Importances:\\n\", importances.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "mroMSB50zzS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q30: Train an ensemble model using both Bagging and Random Forest and compare accuracy\n",
        "# Bagging\n",
        "bag_model = BaggingClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_model.fit(X_train, y_train)\n",
        "bag_acc = accuracy_score(y_test, bag_model.predict(X_test))\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
        "\n",
        "print(\"Bagging Model Accuracy:\", bag_acc)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)"
      ],
      "metadata": {
        "id": "w-aej1Tpz3dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q31 Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "\n",
        "#Answer (brief): Use GridSearchCV to search parameters like n_estimators, max_depth, max_features, and min_samples_split; use a pipeline or direct RF with stratified CV and pick metrics (accuracy, f1).\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'max_features': ['sqrt', 'log2', 0.5],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1, scoring='f1')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "best = grid.best_estimator_\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, best.predict(X_test)))"
      ],
      "metadata": {
        "id": "ETdJfB4LL57y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q32 Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "\n",
        "#Answer (brief): Vary n_estimators and compute MSE on test set; plot or print to compare.\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "for n in [5, 10, 30, 50, 100]:\n",
        "    model = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    print(f\"n_estimators={n} -> MSE: {mean_squared_error(y_test, pred):.4f}\")"
      ],
      "metadata": {
        "id": "2kFPF5vfMEGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q33 Train a Random Forest Classifier and analyze misclassified samples.\n",
        "\n",
        "#Answer (brief): Train RF, predict on test set, locate indices where y_true != y_pred, inspect features or texts for those rows to understand errors.\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "mis_idx = [i for i,(t,p) in enumerate(zip(y_test, y_pred)) if t!=p]\n",
        "df_mis = pd.DataFrame(X_test[mis_idx], columns=data.feature_names)\n",
        "df_mis['true'] = [y_test[i] for i in mis_idx]\n",
        "df_mis['pred'] = [y_pred[i] for i in mis_idx]\n",
        "print(\"Misclassified samples (features):\\n\", df_mis)"
      ],
      "metadata": {
        "id": "Cr7cb-g9MkoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q34 Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "\n",
        "#Answer (brief): Fit both on same train/test split; compare accuracy/precision/recall or cross-validated scores.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "bag_pred = bag.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree acc:\", accuracy_score(y_test, dt_pred))\n",
        "print(\"Bagging acc:\", accuracy_score(y_test, bag_pred))\n",
        "print(\"\\nBagging classification report:\\n\", classification_report(y_test, bag_pred))"
      ],
      "metadata": {
        "id": "cortRhmAMu79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q35 Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "\n",
        "#Answer (brief): Use confusion_matrix and ConfusionMatrixDisplay (or seaborn heatmap) to visualize errors across classes.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['neg','pos'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xk_faBAoM3yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q36 Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
        "\n",
        "#Answer (brief): Use StackingClassifier with base learners and a final estimator (e.g., LogisticRegression), compare to individual learners.\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=42)),\n",
        "    ('svm', SVC(kernel='rbf', probability=True, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), n_jobs=-1)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking accuracy:\", accuracy_score(y_test, stack.predict(X_test)))\n",
        "\n",
        "# Compare single RandomForest for baseline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"RandomForest accuracy:\", accuracy_score(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "id": "ShG1YyADM-SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q37 Train a Random Forest Classifier and print the top 5 most important features.\n",
        "\n",
        "#Answer (brief): After training, sort feature_importances_ and print top-5 with names.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42, stratify=data.target)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "fi = pd.Series(rf.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
        "print(\"Top 5 features:\\n\", fi.head(5))"
      ],
      "metadata": {
        "id": "YVcc0XQaNIXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q38 Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
        "\n",
        "#Answer (brief): Use classification_report or compute metrics individually for test set predictions.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "y_pred = bag.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "W7eFixswNXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q39 Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
        "\n",
        "#Answer (brief): Sweep max_depth values, record CV or test accuracies, then plot/print to analyze bias-variance tradeoff.\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "for depth in [None, 2, 4, 6, 8, 10]:\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
        "    print(f\"max_depth={depth} -> Test accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "LF-yMwRyNgeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q40 Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
        "\n",
        "#Answer (brief): Fit bagging with two different base estimators and compare MSE or R² on test set.\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for base in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
        "    bag = BaggingRegressor(base_estimator=base, n_estimators=50, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    pred = bag.predict(X_test)\n",
        "    print(f\"Base: {base.__class__.__name__} -> MSE: {mean_squared_error(y_test, pred):.4f}\")"
      ],
      "metadata": {
        "id": "I8nZKMMJNolp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q41 Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "\n",
        "#Answer (brief): Use predict_proba or decision_function and roc_auc_score. For multiclass, use ovr or macro averaging.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))"
      ],
      "metadata": {
        "id": "pIZbXKLdN3zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q42 Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "\n",
        "#Answer (brief): Use cross_val_score with stratified folds and metrics like accuracy or f1.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "scores = cross_val_score(bag, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(\"Cross-val accuracies:\", scores)\n",
        "print(\"Mean accuracy:\", scores.mean())"
      ],
      "metadata": {
        "id": "5fwO01kROA-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q43 Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
        "\n",
        "#Answer (brief): Use precision_recall_curve and plot precision vs recall for the positive class; compute average precision.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "prec, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "ap = average_precision_score(y_test, y_prob)\n",
        "\n",
        "plt.plot(recall, prec)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(f\"Precision-Recall curve (AP={ap:.3f})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xl9IYZepOKXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q44 Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
        "\n",
        "#Answer (brief): Stacking can combine RF and LR as base learners (and possibly others); the meta-learner blends their predictions for final output.\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), n_jobs=-1)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking accuracy:\", accuracy_score(y_test, stack.predict(X_test)))\n",
        "\n",
        "# Compare with best single model (RF)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"RandomForest accuracy:\", accuracy_score(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "id": "kOWZEOr8OS69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q45 Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "\n",
        "#Answer (brief): Vary bootstrap (True/False) or change sample sizes with max_samples to see effect on performance and variance.\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for max_samples in [0.5, 0.7, 1.0]:\n",
        "    bag = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50,\n",
        "                           bootstrap=True, max_samples=max_samples, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    pred = bag.predict(X_test)\n",
        "    print(f\"bootstrap=True, max_samples={max_samples} -> MSE: {mean_squared_error(y_test, pred):.4f}\")\n",
        "\n",
        "# Also try bootstrap=False for comparison\n",
        "bag_nb = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50,\n",
        "                         bootstrap=False, random_state=42)\n",
        "bag_nb.fit(X_train, y_train)\n",
        "print(\"bootstrap=False -> MSE:\", mean_squared_error(y_test, bag_nb.predict(X_test)))"
      ],
      "metadata": {
        "id": "aK9trHf7Ohw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}